{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed764bec",
   "metadata": {},
   "source": [
    "Khai bÃ¡o thÆ° viá»‡n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bee67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cade106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cáº¥u hÃ¬nh\n",
    "IMG_SIZE = 128  # TÄƒng lÃªn 128 cho transfer learning\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae620eff",
   "metadata": {},
   "source": [
    "Chuáº©n bá»‹ dá»¯ liá»‡u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fdabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_dir):\n",
    "    \"\"\"Táº¡o dataset tá»« thÆ° má»¥c images/train vÃ  images/valid\"\"\"\n",
    "    train_dir = Path(data_dir) / 'train'\n",
    "    valid_dir = Path(data_dir) / 'valid'\n",
    "    \n",
    "    if not train_dir.exists():\n",
    "        raise ValueError(f\"ThÆ° má»¥c train khÃ´ng tá»“n táº¡i: {train_dir}\")\n",
    "    if not valid_dir.exists():\n",
    "        raise ValueError(f\"ThÆ° má»¥c valid khÃ´ng tá»“n táº¡i: {valid_dir}\")\n",
    "    \n",
    "    def load_from_dir(directory):\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "        \n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "            image_paths.extend(directory.glob(ext))\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            filename = img_path.stem.lower()\n",
    "            if 'fall' in filename and 'not' not in filename:\n",
    "                labels.append(1)  # Fall\n",
    "            else:\n",
    "                labels.append(0)  # Not fall\n",
    "        \n",
    "        return [str(p) for p in image_paths], np.array(labels)\n",
    "    \n",
    "    train_paths, train_labels = load_from_dir(train_dir)\n",
    "    val_paths, val_labels = load_from_dir(valid_dir)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING SET: {len(train_paths)} images\")\n",
    "    print(f\"  - Fall: {sum(train_labels)} ({sum(train_labels)/len(train_labels)*100:.1f}%)\")\n",
    "    print(f\"  - Not Fall: {len(train_labels)-sum(train_labels)} ({(len(train_labels)-sum(train_labels))/len(train_labels)*100:.1f}%)\")\n",
    "    print(f\"\\nVALIDATION SET: {len(val_paths)} images\")\n",
    "    print(f\"  - Fall: {sum(val_labels)} ({sum(val_labels)/len(val_labels)*100:.1f}%)\")\n",
    "    print(f\"  - Not Fall: {len(val_labels)-sum(val_labels)} ({(len(val_labels)-sum(val_labels))/len(val_labels)*100:.1f}%)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    if len(train_paths) == 0:\n",
    "        raise ValueError(f\"KhÃ´ng tÃ¬m tháº¥y áº£nh trong {train_dir}\")\n",
    "    if len(val_paths) == 0:\n",
    "        raise ValueError(f\"KhÃ´ng tÃ¬m tháº¥y áº£nh trong {valid_dir}\")\n",
    "    \n",
    "    return train_paths, train_labels, val_paths, val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30517193",
   "metadata": {},
   "source": [
    "Tiá»n xá»­ lÃ½ hÃ¬nh áº£nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ce3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path, label):\n",
    "    \"\"\"Load vÃ  tiá»n xá»­ lÃ½ áº£nh\"\"\"\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "    img = img / 255.0\n",
    "    return img, label\n",
    "\n",
    "def augment_image(img, label):\n",
    "    \"\"\"Data augmentation\"\"\"\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_brightness(img, 0.2)\n",
    "    img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "    img = tf.clip_by_value(img, 0.0, 1.0)\n",
    "    return img, label\n",
    "\n",
    "def create_tf_dataset(paths, labels, is_training=True):\n",
    "    \"\"\"Táº¡o TensorFlow dataset\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(1000)\n",
    "        dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.repeat()\n",
    "    \n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb88e74",
   "metadata": {},
   "source": [
    "Khai bÃ¡o cÃ¡c kiáº¿n trÃºc mÃ´ hÃ¬nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfecb90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_cnn():\n",
    "    \"\"\"MÃ´ hÃ¬nh CNN Ä‘Æ¡n giáº£n - nhá» nháº¥t\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        \n",
    "        layers.Conv2D(16, 3, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(2),\n",
    "        \n",
    "        layers.Conv2D(32, 3, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(2),\n",
    "        \n",
    "        layers.Conv2D(64, 3, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ], name='SimpleCNN')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mobilenetv2_model():\n",
    "    \"\"\"MobileNetV2 - Transfer Learning (RECOMMENDED cho ESP32)\"\"\"\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        alpha=0.35  # Version nhá» nháº¥t cá»§a MobileNetV2\n",
    "    )\n",
    "    \n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "    # ThÃªm cÃ¡c lá»›p tÃ¹y chá»‰nh phÃ­a trÃªn base model\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ], name='MobileNetV2')\n",
    "    \n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3361db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_efficientnet_model():\n",
    "    \"\"\"EfficientNetB0 - Hiá»‡u quáº£ cao\"\"\"\n",
    "    base_model = EfficientNetB0(\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ], name='EfficientNetB0')\n",
    "    \n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ae4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_cnn():\n",
    "    \"\"\"Custom CNN - CÃ¢n báº±ng giá»¯a kÃ­ch thÆ°á»›c vÃ  hiá»‡u suáº¥t\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        \n",
    "        # Block 1\n",
    "        layers.Conv2D(24, 3, strides=2, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Block 2\n",
    "        layers.Conv2D(48, 3, strides=2, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Block 3\n",
    "        layers.Conv2D(96, 3, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Block 4\n",
    "        layers.Conv2D(128, 3, padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Classifier\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ], name='CustomCNN')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a569d2de",
   "metadata": {},
   "source": [
    "Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Váº½ biá»ƒu Ä‘á»“ training history\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Loss\n",
    "    ax1.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    ax1.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title(f'{model_name} - Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    ax2.plot(history.history['accuracy'], label='Train Acc', linewidth=2)\n",
    "    ax2.plot(history.history['val_accuracy'], label='Val Acc', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax2.set_title(f'{model_name} - Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'history_{model_name.lower().replace(\" \", \"_\")}.png'\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    print(f\"  ğŸ“Š Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "def train_model(model_name, data_dir):\n",
    "    \"\"\"Train mÃ´ hÃ¬nh\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸš€ TRAINING: {model_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Load data\n",
    "    train_paths, train_labels, val_paths, val_labels = create_dataset(data_dir)\n",
    "    \n",
    "    steps_per_epoch = len(train_paths) // BATCH_SIZE\n",
    "    validation_steps = len(val_paths) // BATCH_SIZE\n",
    "    \n",
    "    train_ds = create_tf_dataset(train_paths, train_labels, is_training=True)\n",
    "    val_ds = create_tf_dataset(val_paths, val_labels, is_training=False)\n",
    "    \n",
    "    # Create model\n",
    "    base_model = None\n",
    "    if model_name == 'MobileNetV2':\n",
    "        model, base_model = create_mobilenetv2_model()\n",
    "    elif model_name == 'EfficientNetB0':\n",
    "        model, base_model = create_efficientnet_model()\n",
    "    elif model_name == 'CustomCNN':\n",
    "        model = create_custom_cnn()\n",
    "    else:  # SimpleCNN\n",
    "        model = create_simple_cnn()\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # Class weights\n",
    "    total = len(train_labels)\n",
    "    n_fall = sum(train_labels)\n",
    "    n_not_fall = total - n_fall\n",
    "    \n",
    "    if n_fall > 0 and n_not_fall > 0:\n",
    "        weight_for_fall = (1 / n_fall) * (total / 2.0)\n",
    "        weight_for_not_fall = (1 / n_not_fall) * (total / 2.0)\n",
    "        class_weight = {0: weight_for_not_fall, 1: weight_for_fall}\n",
    "    else:\n",
    "        class_weight = None\n",
    "    \n",
    "    # Compile\n",
    "    # Chuáº©n bá»‹ mÃ´ hÃ¬nh, Ä‘á»‹nh nghÄ©a cÃ¡ch mÃ´ hÃ¬nh há»c\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', \n",
    "                 keras.metrics.Precision(name='precision'),\n",
    "                 keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    # CÃ¡c hÃ m há»— trá»£ quÃ¡ trÃ¬nh giÃ¡m sÃ¡t, Ä‘iá»u chá»‰nh há»c táº­p\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=8,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            f'best_{model_name.lower()}.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=0\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=validation_steps,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fine-tuning for transfer learning models\n",
    "    if base_model is not None:\n",
    "        print(f\"\\nğŸ”§ Fine-tuning {model_name}...\")\n",
    "        base_model.trainable = True\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for layer in base_model.layers[:-30]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', \n",
    "                     keras.metrics.Precision(name='precision'),\n",
    "                     keras.metrics.Recall(name='recall')]\n",
    "        )\n",
    "        \n",
    "        history_fine = model.fit(\n",
    "            train_ds,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=val_ds,\n",
    "            validation_steps=validation_steps,\n",
    "            epochs=30,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=class_weight,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Merge histories\n",
    "        for key in history.history.keys():\n",
    "            history.history[key].extend(history_fine.history[key])\n",
    "    \n",
    "    # Plot\n",
    "    plot_training_history(history, model_name)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_results = model.evaluate(val_ds, steps=validation_steps, verbose=0)\n",
    "    \n",
    "    return model, history, val_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1b94f7",
   "metadata": {},
   "source": [
    "Tá»‘i Æ°u mÃ´ hÃ¬nh Ä‘á»ƒ deploy thÃ´ng qua tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tflite(model, model_name):\n",
    "    \"\"\"Chuyá»ƒn Ä‘á»•i sang TFLite\"\"\"\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    \n",
    "    # Láº¥y táº­p máº«u ngáº«u nhiÃªn Ä‘á»ƒ tÃ­nh giÃ¡ trá»‹ scale vÃ  zero-point Ä‘á»ƒ chuyá»ƒn Ä‘á»•i sang INT8\n",
    "    def representative_dataset():\n",
    "        for _ in range(100):\n",
    "            data = np.random.rand(1, IMG_SIZE, IMG_SIZE, 3).astype(np.float32)\n",
    "            yield [data]\n",
    "    \n",
    "    converter.representative_dataset = representative_dataset\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    output_path = f'{model_name.lower()}_model.tflite'\n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    size_kb = len(tflite_model) / 1024\n",
    "    \n",
    "    return output_path, size_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee9741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ”¬ EXPERIMENT: So sÃ¡nh cÃ¡c kiáº¿n trÃºc mÃ´ hÃ¬nh\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸš€ TRAINING: MobileNetV2\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "TRAINING SET: 748 images\n",
      "  - Fall: 416 (55.6%)\n",
      "  - Not Fall: 332 (44.4%)\n",
      "\n",
      "VALIDATION SET: 222 images\n",
      "  - Fall: 140 (63.1%)\n",
      "  - Not Fall: 82 (36.9%)\n",
      "============================================================\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_0.35_128_no_top.h5\n",
      "\u001b[1m2019640/2019640\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MobileNetV2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MobileNetV2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ mobilenetv2_0.35_128            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">410,208</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_5      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,992</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ mobilenetv2_0.35_128            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚       \u001b[38;5;34m410,208\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_5      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚        \u001b[38;5;34m40,992\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">451,233</span> (1.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m451,233\u001b[0m (1.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,025</span> (160.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,025\u001b[0m (160.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">410,208</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m410,208\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m45/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7027 - loss: 0.6475 - precision: 0.7241 - recall: 0.6882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 132ms/step - accuracy: 0.7609 - loss: 0.5162 - precision: 0.7868 - recall: 0.7829 - val_accuracy: 0.7163 - val_loss: 0.5680 - val_precision: 0.8092 - val_recall: 0.7571 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8572 - loss: 0.3455 - precision: 0.8819 - recall: 0.8484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.8723 - loss: 0.3052 - precision: 0.8908 - recall: 0.8778 - val_accuracy: 0.7933 - val_loss: 0.4830 - val_precision: 0.8299 - val_recall: 0.8714 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8986 - loss: 0.2432 - precision: 0.9155 - recall: 0.9011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.9022 - loss: 0.2398 - precision: 0.9060 - recall: 0.9193 - val_accuracy: 0.7981 - val_loss: 0.4284 - val_precision: 0.8451 - val_recall: 0.8571 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.9293 - loss: 0.1705 - precision: 0.9435 - recall: 0.9298 - val_accuracy: 0.7740 - val_loss: 0.5015 - val_precision: 0.7925 - val_recall: 0.9000 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.9443 - loss: 0.1414 - precision: 0.9472 - recall: 0.9541 - val_accuracy: 0.7740 - val_loss: 0.5480 - val_precision: 0.8163 - val_recall: 0.8571 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.9443 - loss: 0.1379 - precision: 0.9570 - recall: 0.9403 - val_accuracy: 0.7740 - val_loss: 0.4876 - val_precision: 0.8252 - val_recall: 0.8429 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.9633 - loss: 0.1004 - precision: 0.9684 - recall: 0.9661 - val_accuracy: 0.7692 - val_loss: 0.5169 - val_precision: 0.8194 - val_recall: 0.8429 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.9715 - loss: 0.0788 - precision: 0.9750 - recall: 0.9726 - val_accuracy: 0.7933 - val_loss: 0.5618 - val_precision: 0.8212 - val_recall: 0.8857 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.9660 - loss: 0.0859 - precision: 0.9734 - recall: 0.9663 - val_accuracy: 0.7981 - val_loss: 0.5712 - val_precision: 0.8267 - val_recall: 0.8857 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9639 - loss: 0.0896 - precision: 0.9654 - recall: 0.9683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9660 - loss: 0.0897 - precision: 0.9707 - recall: 0.9684 - val_accuracy: 0.8077 - val_loss: 0.5522 - val_precision: 0.8378 - val_recall: 0.8857 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9871 - loss: 0.0566 - precision: 0.9812 - recall: 0.9955\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.9851 - loss: 0.0570 - precision: 0.9829 - recall: 0.9901 - val_accuracy: 0.8221 - val_loss: 0.6526 - val_precision: 0.8280 - val_recall: 0.9286 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9878 - loss: 0.0434 - precision: 0.9926 - recall: 0.9853 - val_accuracy: 0.7933 - val_loss: 0.6556 - val_precision: 0.8129 - val_recall: 0.9000 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.9783 - loss: 0.0618 - precision: 0.9804 - recall: 0.9804 - val_accuracy: 0.8077 - val_loss: 0.5903 - val_precision: 0.8289 - val_recall: 0.9000 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.9851 - loss: 0.0540 - precision: 0.9852 - recall: 0.9877 - val_accuracy: 0.8029 - val_loss: 0.5946 - val_precision: 0.8235 - val_recall: 0.9000 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.9851 - loss: 0.0629 - precision: 0.9828 - recall: 0.9901 - val_accuracy: 0.8125 - val_loss: 0.5937 - val_precision: 0.8258 - val_recall: 0.9143 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.9769 - loss: 0.0603 - precision: 0.9853 - recall: 0.9734 - val_accuracy: 0.8029 - val_loss: 0.5920 - val_precision: 0.8153 - val_recall: 0.9143 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9851 - loss: 0.0501 - precision: 0.9830 - recall: 0.9902 - val_accuracy: 0.7981 - val_loss: 0.6294 - val_precision: 0.8267 - val_recall: 0.8857 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.9851 - loss: 0.0446 - precision: 0.9854 - recall: 0.9878 - val_accuracy: 0.7981 - val_loss: 0.6362 - val_precision: 0.8182 - val_recall: 0.9000 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9973 - loss: 0.0288 - precision: 0.9962 - recall: 0.9990\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.9918 - loss: 0.0339 - precision: 0.9904 - recall: 0.9952 - val_accuracy: 0.8077 - val_loss: 0.6375 - val_precision: 0.8378 - val_recall: 0.8857 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.9932 - loss: 0.0329 - precision: 0.9951 - recall: 0.9927 - val_accuracy: 0.8125 - val_loss: 0.7059 - val_precision: 0.8258 - val_recall: 0.9143 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.9891 - loss: 0.0375 - precision: 0.9856 - recall: 0.9952 - val_accuracy: 0.7981 - val_loss: 0.6694 - val_precision: 0.8267 - val_recall: 0.8857 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.9891 - loss: 0.0371 - precision: 0.9925 - recall: 0.9876 - val_accuracy: 0.8029 - val_loss: 0.6721 - val_precision: 0.8235 - val_recall: 0.9000 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.9864 - loss: 0.0369 - precision: 0.9904 - recall: 0.9856 - val_accuracy: 0.8125 - val_loss: 0.6937 - val_precision: 0.8258 - val_recall: 0.9143 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.9918 - loss: 0.0276 - precision: 0.9927 - recall: 0.9927 - val_accuracy: 0.8029 - val_loss: 0.7326 - val_precision: 0.8153 - val_recall: 0.9143 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.9946 - loss: 0.0293 - precision: 0.9950 - recall: 0.9950 - val_accuracy: 0.8029 - val_loss: 0.7241 - val_precision: 0.8235 - val_recall: 0.9000 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.9932 - loss: 0.0275 - precision: 0.9953 - recall: 0.9930 - val_accuracy: 0.8077 - val_loss: 0.6955 - val_precision: 0.8289 - val_recall: 0.9000 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9868 - loss: 0.0292 - precision: 0.9835 - recall: 0.9896\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.9918 - loss: 0.0238 - precision: 0.9926 - recall: 0.9926 - val_accuracy: 0.8077 - val_loss: 0.6897 - val_precision: 0.8289 - val_recall: 0.9000 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.9973 - loss: 0.0223 - precision: 0.9950 - recall: 1.0000 - val_accuracy: 0.8077 - val_loss: 0.6920 - val_precision: 0.8289 - val_recall: 0.9000 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9946 - loss: 0.0261 - precision: 1.0000 - recall: 0.9902 - val_accuracy: 0.8125 - val_loss: 0.7348 - val_precision: 0.8258 - val_recall: 0.9143 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.9851 - loss: 0.0383 - precision: 0.9880 - recall: 0.9856 - val_accuracy: 0.8029 - val_loss: 0.7074 - val_precision: 0.8235 - val_recall: 0.9000 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.9891 - loss: 0.0329 - precision: 0.9902 - recall: 0.9902 - val_accuracy: 0.8077 - val_loss: 0.6959 - val_precision: 0.8289 - val_recall: 0.9000 - learning_rate: 1.2500e-04\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\n",
      "ğŸ”§ Fine-tuning MobileNetV2...\n",
      "Epoch 1/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 136ms/step - accuracy: 0.9185 - loss: 0.1951 - precision: 0.9377 - recall: 0.9148 - val_accuracy: 0.8173 - val_loss: 0.5397 - val_precision: 0.9048 - val_recall: 0.8143 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9457 - loss: 0.1261 - precision: 0.9399 - recall: 0.9631 - val_accuracy: 0.7885 - val_loss: 0.5897 - val_precision: 0.9138 - val_recall: 0.7571 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9775 - loss: 0.0630 - precision: 0.9947 - recall: 0.9665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.9755 - loss: 0.0707 - precision: 0.9877 - recall: 0.9685 - val_accuracy: 0.8269 - val_loss: 0.5670 - val_precision: 0.9194 - val_recall: 0.8143 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9783 - loss: 0.0711 - precision: 0.9826 - recall: 0.9777 - val_accuracy: 0.8173 - val_loss: 0.5489 - val_precision: 0.9180 - val_recall: 0.8000 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.9837 - loss: 0.0497 - precision: 0.9854 - recall: 0.9854 - val_accuracy: 0.8173 - val_loss: 0.5504 - val_precision: 0.9474 - val_recall: 0.7714 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.9783 - loss: 0.0627 - precision: 0.9828 - recall: 0.9780 - val_accuracy: 0.7885 - val_loss: 0.6056 - val_precision: 0.9444 - val_recall: 0.7286 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.9851 - loss: 0.0595 - precision: 0.9854 - recall: 0.9878 - val_accuracy: 0.8029 - val_loss: 0.6642 - val_precision: 0.9714 - val_recall: 0.7286 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9818 - loss: 0.0627 - precision: 0.9893 - recall: 0.9791\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - accuracy: 0.9878 - loss: 0.0405 - precision: 0.9903 - recall: 0.9879 - val_accuracy: 0.7981 - val_loss: 0.5974 - val_precision: 0.9455 - val_recall: 0.7429 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.9973 - loss: 0.0174 - precision: 1.0000 - recall: 0.9951 - val_accuracy: 0.8077 - val_loss: 0.5587 - val_precision: 0.9464 - val_recall: 0.7571 - learning_rate: 5.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - accuracy: 0.9932 - loss: 0.0202 - precision: 0.9975 - recall: 0.9900 - val_accuracy: 0.8269 - val_loss: 0.5308 - val_precision: 0.9483 - val_recall: 0.7857 - learning_rate: 5.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.9878 - loss: 0.0315 - precision: 0.9857 - recall: 0.9928 - val_accuracy: 0.8173 - val_loss: 0.5463 - val_precision: 0.9322 - val_recall: 0.7857 - learning_rate: 5.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.9959 - loss: 0.0177 - precision: 1.0000 - recall: 0.9926 - val_accuracy: 0.8173 - val_loss: 0.5527 - val_precision: 0.9322 - val_recall: 0.7857 - learning_rate: 5.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9946 - loss: 0.0219 - precision: 0.9927 - recall: 0.9975 - val_accuracy: 0.8077 - val_loss: 0.6074 - val_precision: 0.9310 - val_recall: 0.7714 - learning_rate: 5.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.9946 - loss: 0.0178 - precision: 0.9929 - recall: 0.9976 - val_accuracy: 0.8077 - val_loss: 0.5828 - val_precision: 0.9310 - val_recall: 0.7714 - learning_rate: 5.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.9891 - loss: 0.0276 - precision: 0.9925 - recall: 0.9875 - val_accuracy: 0.7981 - val_loss: 0.6056 - val_precision: 0.9153 - val_recall: 0.7714 - learning_rate: 5.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9948 - loss: 0.0190 - precision: 0.9984 - recall: 0.9922\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9932 - loss: 0.0244 - precision: 0.9976 - recall: 0.9906 - val_accuracy: 0.7885 - val_loss: 0.6370 - val_precision: 0.9138 - val_recall: 0.7571 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9878 - loss: 0.0322 - precision: 0.9873 - recall: 0.9898 - val_accuracy: 0.7885 - val_loss: 0.6462 - val_precision: 0.9138 - val_recall: 0.7571 - learning_rate: 2.5000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.9973 - loss: 0.0107 - precision: 0.9975 - recall: 0.9975 - val_accuracy: 0.8077 - val_loss: 0.6382 - val_precision: 0.9167 - val_recall: 0.7857 - learning_rate: 2.5000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.9905 - loss: 0.0287 - precision: 0.9929 - recall: 0.9905 - val_accuracy: 0.8269 - val_loss: 0.5928 - val_precision: 0.9194 - val_recall: 0.8143 - learning_rate: 2.5000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0090 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.8269 - val_loss: 0.5883 - val_precision: 0.9194 - val_recall: 0.8143 - learning_rate: 2.5000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9946 - loss: 0.0173 - precision: 0.9951 - recall: 0.9951 - val_accuracy: 0.8029 - val_loss: 0.6130 - val_precision: 0.8837 - val_recall: 0.8143 - learning_rate: 2.5000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9878 - loss: 0.0353 - precision: 0.9877 - recall: 0.9901 - val_accuracy: 0.8269 - val_loss: 0.5897 - val_precision: 0.9194 - val_recall: 0.8143 - learning_rate: 2.5000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0094 - precision: 1.0000 - recall: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0110 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.8365 - val_loss: 0.5746 - val_precision: 0.9077 - val_recall: 0.8429 - learning_rate: 2.5000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9940 - loss: 0.0106 - precision: 0.9983 - recall: 0.9908\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9932 - loss: 0.0150 - precision: 0.9951 - recall: 0.9927 - val_accuracy: 0.8221 - val_loss: 0.5716 - val_precision: 0.8872 - val_recall: 0.8429 - learning_rate: 2.5000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9986 - loss: 0.0080 - precision: 0.9976 - recall: 1.0000 - val_accuracy: 0.8221 - val_loss: 0.5807 - val_precision: 0.8872 - val_recall: 0.8429 - learning_rate: 1.2500e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.9959 - loss: 0.0184 - precision: 0.9951 - recall: 0.9976 - val_accuracy: 0.8269 - val_loss: 0.5854 - val_precision: 0.8824 - val_recall: 0.8571 - learning_rate: 1.2500e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9918 - loss: 0.0259 - precision: 0.9851 - recall: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.9932 - loss: 0.0241 - precision: 0.9877 - recall: 1.0000 - val_accuracy: 0.8413 - val_loss: 0.5944 - val_precision: 0.9023 - val_recall: 0.8571 - learning_rate: 1.2500e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.9973 - loss: 0.0138 - precision: 0.9951 - recall: 1.0000 - val_accuracy: 0.8269 - val_loss: 0.6010 - val_precision: 0.8824 - val_recall: 0.8571 - learning_rate: 1.2500e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.9973 - loss: 0.0106 - precision: 0.9974 - recall: 0.9974 - val_accuracy: 0.8269 - val_loss: 0.6170 - val_precision: 0.8824 - val_recall: 0.8571 - learning_rate: 1.2500e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9946 - loss: 0.0183 - precision: 0.9952 - recall: 0.9952 - val_accuracy: 0.8173 - val_loss: 0.6341 - val_precision: 0.8806 - val_recall: 0.8429 - learning_rate: 1.2500e-05\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "  ğŸ“Š Saved: history_mobilenetv2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp_l86dyrh\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp_l86dyrh\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp_l86dyrh'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='keras_tensor_221')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1515548968144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548970064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548969680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548969488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548970448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548968336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548971408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548972560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548973328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548974288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548971792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548968528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548973520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548971024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548970256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548974480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656176144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656180752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548969296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548971216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656174992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656174032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656181136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656174608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656178832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656180176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656179408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656179024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656179984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656178064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656179216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656178640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656178448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656175184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656175760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656178256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656176528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656177680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656180368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656176720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656176912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656177488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656177296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656179600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656180944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656173840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656173648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656179792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656177872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656183632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515715821392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656183248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656177104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515715813328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656180560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656183440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959976784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959977552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656183056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515656176336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959977360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959978320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959978128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959977744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959979472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959978896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959979088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959979280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959978512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959980432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959979856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959980048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959980240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959977936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959981392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959980816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959981008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959981200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959978704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959982352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959981776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959981968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959982160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959979664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959983312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959982736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959982928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959983120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959980624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959984272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959983696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959983888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959984080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959981584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959985232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959984656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959984848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959985040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959982544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959986192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959985616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959985808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959986000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959983504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959987152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959986576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959986768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959986960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959984464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959988112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959987536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959987728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959987920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959985424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959989072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959988496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959988688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959988880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959986384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959990032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959989456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959989648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959989840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959987344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959990992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959990416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959990608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959990800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959988304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959991952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959991376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959990224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959991760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959991568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959991184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959989264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711087056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711088208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515959992144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711087632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711088016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711086672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711086864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711087248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711089168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711088592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711088784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711088976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711087824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711090128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711089552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711089744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711089936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711087440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711091088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711090512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711090704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711090896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711088400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711092048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711091472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711091664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711091856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711089360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711093008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711092432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711092624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711092816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711090320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711093968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711093392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711093584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711093776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711091280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711094928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711094352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711094544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711094736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711092240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711095888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711095312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711095504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711095696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711093200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711096848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711096272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711096464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711096656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711094160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711097808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711097232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711097424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711097616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711095120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711098768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711098192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711098384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711098576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711096080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711099728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711099152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711099344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711099536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711097040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711100688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711100112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711100304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711100496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711098000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711101648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711101072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711101264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711101456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711098960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711102608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711102032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711100880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711102416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711102224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711101840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711099920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661918480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661918864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515711102800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661919824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661918288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661919440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661919632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661919248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661920784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661920208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661920400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661920592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661918672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661921744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661921168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661921360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661921552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661919056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661922704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661922128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661922320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661922512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661920016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661923664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661923088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661923280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661923472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661920976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661924624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661924048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661924240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661924432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661921936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661925584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661925008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661925200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661925392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661922896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661926544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661926736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661927504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661928464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515661927696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… MobileNetV2 hoÃ n thÃ nh!\n",
      "   Accuracy: 0.8413\n",
      "   Size: 647.43 KB\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸš€ TRAINING: CustomCNN\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "TRAINING SET: 748 images\n",
      "  - Fall: 416 (55.6%)\n",
      "  - Not Fall: 332 (44.4%)\n",
      "\n",
      "VALIDATION SET: 222 images\n",
      "  - Fall: 140 (63.1%)\n",
      "  - Not Fall: 82 (36.9%)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CustomCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CustomCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">648</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_15          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_16          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,472</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_17          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">110,592</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_18          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_6      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m24\u001b[0m)     â”‚           \u001b[38;5;34m648\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_15          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m24\u001b[0m)     â”‚            \u001b[38;5;34m96\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m24\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m24\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m)     â”‚        \u001b[38;5;34m10,368\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_16          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m)     â”‚           \u001b[38;5;34m192\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m96\u001b[0m)     â”‚        \u001b[38;5;34m41,472\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_17          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m96\u001b[0m)     â”‚           \u001b[38;5;34m384\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m96\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m96\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚       \u001b[38;5;34m110,592\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_18          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_6      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_12 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_13 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">172,585</span> (674.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m172,585\u001b[0m (674.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">171,993</span> (671.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m171,993\u001b[0m (671.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">592</span> (2.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m592\u001b[0m (2.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.5215 - loss: 0.7672 - precision: 0.5680 - recall: 0.4883"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 258ms/step - accuracy: 0.5584 - loss: 0.7387 - precision: 0.6162 - recall: 0.5547 - val_accuracy: 0.6731 - val_loss: 0.6304 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 237ms/step - accuracy: 0.6128 - loss: 0.6643 - precision: 0.6630 - recall: 0.6025 - val_accuracy: 0.6731 - val_loss: 0.7359 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 240ms/step - accuracy: 0.6141 - loss: 0.6566 - precision: 0.6739 - recall: 0.6053 - val_accuracy: 0.6731 - val_loss: 0.8391 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 261ms/step - accuracy: 0.6223 - loss: 0.6467 - precision: 0.6789 - recall: 0.6232 - val_accuracy: 0.6635 - val_loss: 0.9635 - val_precision: 0.6699 - val_recall: 0.9857 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 276ms/step - accuracy: 0.6807 - loss: 0.6067 - precision: 0.7416 - recall: 0.6486 - val_accuracy: 0.6731 - val_loss: 1.2807 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 276ms/step - accuracy: 0.6495 - loss: 0.6280 - precision: 0.7160 - recall: 0.5910 - val_accuracy: 0.6442 - val_loss: 0.9345 - val_precision: 0.6634 - val_recall: 0.9571 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 299ms/step - accuracy: 0.6739 - loss: 0.6149 - precision: 0.7406 - recall: 0.6314 - val_accuracy: 0.6731 - val_loss: 1.2703 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 299ms/step - accuracy: 0.6576 - loss: 0.6084 - precision: 0.7391 - recall: 0.6115 - val_accuracy: 0.5288 - val_loss: 0.6643 - val_precision: 0.6909 - val_recall: 0.5429 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7017 - loss: 0.5756 - precision: 0.7482 - recall: 0.6956\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 300ms/step - accuracy: 0.6997 - loss: 0.5757 - precision: 0.7611 - recall: 0.6699 - val_accuracy: 0.6635 - val_loss: 1.0230 - val_precision: 0.6768 - val_recall: 0.9571 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 281ms/step - accuracy: 0.6821 - loss: 0.5700 - precision: 0.7410 - recall: 0.6577 - val_accuracy: 0.6442 - val_loss: 0.7360 - val_precision: 0.7037 - val_recall: 0.8143 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 261ms/step - accuracy: 0.7473 - loss: 0.5140 - precision: 0.7933 - recall: 0.7433 - val_accuracy: 0.6635 - val_loss: 0.8355 - val_precision: 0.6882 - val_recall: 0.9143 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 270ms/step - accuracy: 0.7582 - loss: 0.5110 - precision: 0.8053 - recall: 0.7420 - val_accuracy: 0.4375 - val_loss: 1.1285 - val_precision: 0.6353 - val_recall: 0.3857 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.7125 - loss: 0.5744 - precision: 0.7366 - recall: 0.7213"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 266ms/step - accuracy: 0.7269 - loss: 0.5422 - precision: 0.7723 - recall: 0.7213 - val_accuracy: 0.6827 - val_loss: 0.8966 - val_precision: 0.6907 - val_recall: 0.9571 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 256ms/step - accuracy: 0.7378 - loss: 0.5283 - precision: 0.7889 - recall: 0.7257 - val_accuracy: 0.6058 - val_loss: 0.6585 - val_precision: 0.6883 - val_recall: 0.7571 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 268ms/step - accuracy: 0.7677 - loss: 0.4976 - precision: 0.7916 - recall: 0.7857 - val_accuracy: 0.6250 - val_loss: 0.6753 - val_precision: 0.7067 - val_recall: 0.7571 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 269ms/step - accuracy: 0.7663 - loss: 0.5030 - precision: 0.7975 - recall: 0.7780 - val_accuracy: 0.4135 - val_loss: 1.2426 - val_precision: 1.0000 - val_recall: 0.1286 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.7865 - loss: 0.4920 - precision: 0.8093 - recall: 0.8008\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 267ms/step - accuracy: 0.7731 - loss: 0.5060 - precision: 0.7990 - recall: 0.7852 - val_accuracy: 0.5000 - val_loss: 0.8697 - val_precision: 0.6731 - val_recall: 0.5000 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 304ms/step - accuracy: 0.8057 - loss: 0.4533 - precision: 0.8425 - recall: 0.8082 - val_accuracy: 0.5865 - val_loss: 0.8075 - val_precision: 0.7143 - val_recall: 0.6429 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 284ms/step - accuracy: 0.7921 - loss: 0.4670 - precision: 0.8221 - recall: 0.8000 - val_accuracy: 0.5288 - val_loss: 1.4086 - val_precision: 0.9565 - val_recall: 0.3143 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 334ms/step - accuracy: 0.8030 - loss: 0.4617 - precision: 0.8308 - recall: 0.8040 - val_accuracy: 0.5385 - val_loss: 0.8177 - val_precision: 0.7037 - val_recall: 0.5429 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 284ms/step - accuracy: 0.7935 - loss: 0.4544 - precision: 0.8063 - recall: 0.8222 - val_accuracy: 0.5481 - val_loss: 0.8222 - val_precision: 0.7091 - val_recall: 0.5571 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 313ms/step - accuracy: 0.7921 - loss: 0.4794 - precision: 0.8338 - recall: 0.7874 - val_accuracy: 0.6827 - val_loss: 0.8881 - val_precision: 0.7079 - val_recall: 0.9000 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 294ms/step - accuracy: 0.8179 - loss: 0.4386 - precision: 0.8382 - recall: 0.8382 - val_accuracy: 0.6635 - val_loss: 1.1017 - val_precision: 0.7059 - val_recall: 0.8571 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 278ms/step - accuracy: 0.7717 - loss: 0.5010 - precision: 0.8111 - recall: 0.7759 - val_accuracy: 0.4856 - val_loss: 0.8560 - val_precision: 0.6897 - val_recall: 0.4286 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.8028 - loss: 0.4527 - precision: 0.8148 - recall: 0.8086\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 260ms/step - accuracy: 0.7989 - loss: 0.4799 - precision: 0.8069 - recall: 0.8026 - val_accuracy: 0.7019 - val_loss: 0.7090 - val_precision: 0.7671 - val_recall: 0.8000 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step - accuracy: 0.8030 - loss: 0.4387 - precision: 0.8507 - recall: 0.8009 - val_accuracy: 0.6058 - val_loss: 0.8911 - val_precision: 0.7377 - val_recall: 0.6429 - learning_rate: 1.2500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 281ms/step - accuracy: 0.8043 - loss: 0.4482 - precision: 0.8221 - recall: 0.8301 - val_accuracy: 0.6731 - val_loss: 0.8583 - val_precision: 0.7432 - val_recall: 0.7857 - learning_rate: 1.2500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 295ms/step - accuracy: 0.8261 - loss: 0.4356 - precision: 0.8568 - recall: 0.8277 - val_accuracy: 0.5673 - val_loss: 1.0248 - val_precision: 0.7193 - val_recall: 0.5857 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 294ms/step - accuracy: 0.8003 - loss: 0.4431 - precision: 0.8092 - recall: 0.8313 - val_accuracy: 0.6827 - val_loss: 1.0940 - val_precision: 0.7176 - val_recall: 0.8714 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 258ms/step - accuracy: 0.8139 - loss: 0.4221 - precision: 0.8462 - recall: 0.8108 - val_accuracy: 0.7019 - val_loss: 1.0657 - val_precision: 0.7191 - val_recall: 0.9143 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.8198 - loss: 0.4169 - precision: 0.8488 - recall: 0.8389"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 252ms/step - accuracy: 0.8274 - loss: 0.4200 - precision: 0.8477 - recall: 0.8415 - val_accuracy: 0.7212 - val_loss: 1.1683 - val_precision: 0.7595 - val_recall: 0.8571 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 251ms/step - accuracy: 0.8057 - loss: 0.4458 - precision: 0.8300 - recall: 0.8157 - val_accuracy: 0.5096 - val_loss: 1.0550 - val_precision: 0.6939 - val_recall: 0.4857 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.7683 - loss: 0.4829 - precision: 0.8197 - recall: 0.7652\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 268ms/step - accuracy: 0.7812 - loss: 0.4774 - precision: 0.8241 - recall: 0.7828 - val_accuracy: 0.7212 - val_loss: 0.7390 - val_precision: 0.7531 - val_recall: 0.8714 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.7931 - loss: 0.4661 - precision: 0.8153 - recall: 0.8147"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 282ms/step - accuracy: 0.8111 - loss: 0.4355 - precision: 0.8284 - recall: 0.8263 - val_accuracy: 0.7308 - val_loss: 1.0913 - val_precision: 0.7442 - val_recall: 0.9143 - learning_rate: 6.2500e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 272ms/step - accuracy: 0.8071 - loss: 0.4411 - precision: 0.8254 - recall: 0.8213 - val_accuracy: 0.6346 - val_loss: 1.0127 - val_precision: 0.7500 - val_recall: 0.6857 - learning_rate: 6.2500e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 277ms/step - accuracy: 0.8302 - loss: 0.3934 - precision: 0.8615 - recall: 0.8301 - val_accuracy: 0.6731 - val_loss: 0.9824 - val_precision: 0.7432 - val_recall: 0.7857 - learning_rate: 6.2500e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 254ms/step - accuracy: 0.8288 - loss: 0.4122 - precision: 0.8617 - recall: 0.8329 - val_accuracy: 0.6058 - val_loss: 0.8884 - val_precision: 0.7377 - val_recall: 0.6429 - learning_rate: 6.2500e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 238ms/step - accuracy: 0.8356 - loss: 0.3995 - precision: 0.8403 - recall: 0.8593 - val_accuracy: 0.6827 - val_loss: 1.0234 - val_precision: 0.7534 - val_recall: 0.7857 - learning_rate: 6.2500e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 242ms/step - accuracy: 0.8383 - loss: 0.4059 - precision: 0.8741 - recall: 0.8389 - val_accuracy: 0.5962 - val_loss: 1.0456 - val_precision: 0.7333 - val_recall: 0.6286 - learning_rate: 6.2500e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 233ms/step - accuracy: 0.8519 - loss: 0.3971 - precision: 0.8747 - recall: 0.8599 - val_accuracy: 0.6346 - val_loss: 0.9405 - val_precision: 0.7286 - val_recall: 0.7286 - learning_rate: 6.2500e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.8303 - loss: 0.4189 - precision: 0.8642 - recall: 0.8132\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 236ms/step - accuracy: 0.8342 - loss: 0.4099 - precision: 0.8718 - recall: 0.8252 - val_accuracy: 0.6058 - val_loss: 0.9684 - val_precision: 0.7377 - val_recall: 0.6429 - learning_rate: 6.2500e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 233ms/step - accuracy: 0.8438 - loss: 0.4009 - precision: 0.8337 - recall: 0.8750 - val_accuracy: 0.6346 - val_loss: 1.0221 - val_precision: 0.7353 - val_recall: 0.7143 - learning_rate: 3.1250e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 240ms/step - accuracy: 0.8234 - loss: 0.4166 - precision: 0.8631 - recall: 0.8267 - val_accuracy: 0.6058 - val_loss: 1.0520 - val_precision: 0.7377 - val_recall: 0.6429 - learning_rate: 3.1250e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 236ms/step - accuracy: 0.8356 - loss: 0.3844 - precision: 0.8578 - recall: 0.8475 - val_accuracy: 0.6538 - val_loss: 0.9688 - val_precision: 0.7429 - val_recall: 0.7429 - learning_rate: 3.1250e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 268ms/step - accuracy: 0.8465 - loss: 0.3962 - precision: 0.8633 - recall: 0.8525 - val_accuracy: 0.5962 - val_loss: 1.0685 - val_precision: 0.7258 - val_recall: 0.6429 - learning_rate: 3.1250e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 268ms/step - accuracy: 0.8302 - loss: 0.4003 - precision: 0.8693 - recall: 0.8258 - val_accuracy: 0.5962 - val_loss: 1.0604 - val_precision: 0.7258 - val_recall: 0.6429 - learning_rate: 3.1250e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 323ms/step - accuracy: 0.8424 - loss: 0.3771 - precision: 0.8597 - recall: 0.8467 - val_accuracy: 0.6731 - val_loss: 0.9957 - val_precision: 0.7432 - val_recall: 0.7857 - learning_rate: 3.1250e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 303ms/step - accuracy: 0.8451 - loss: 0.3875 - precision: 0.8592 - recall: 0.8634 - val_accuracy: 0.5962 - val_loss: 1.0436 - val_precision: 0.7258 - val_recall: 0.6429 - learning_rate: 3.1250e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.8412 - loss: 0.4021 - precision: 0.8548 - recall: 0.8542\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 265ms/step - accuracy: 0.8274 - loss: 0.4036 - precision: 0.8614 - recall: 0.8305 - val_accuracy: 0.6731 - val_loss: 1.0562 - val_precision: 0.7647 - val_recall: 0.7429 - learning_rate: 3.1250e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 255ms/step - accuracy: 0.8234 - loss: 0.4021 - precision: 0.8329 - recall: 0.8494 - val_accuracy: 0.6346 - val_loss: 1.0405 - val_precision: 0.7500 - val_recall: 0.6857 - learning_rate: 1.5625e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 258ms/step - accuracy: 0.8111 - loss: 0.4070 - precision: 0.8300 - recall: 0.8238 - val_accuracy: 0.6346 - val_loss: 1.0889 - val_precision: 0.7500 - val_recall: 0.6857 - learning_rate: 1.5625e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 253ms/step - accuracy: 0.8139 - loss: 0.4021 - precision: 0.8454 - recall: 0.8274 - val_accuracy: 0.6635 - val_loss: 1.1137 - val_precision: 0.7536 - val_recall: 0.7429 - learning_rate: 1.5625e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 246ms/step - accuracy: 0.8614 - loss: 0.3673 - precision: 0.8665 - recall: 0.8837 - val_accuracy: 0.6731 - val_loss: 1.1336 - val_precision: 0.7571 - val_recall: 0.7571 - learning_rate: 1.5625e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 270ms/step - accuracy: 0.8397 - loss: 0.3972 - precision: 0.8589 - recall: 0.8505 - val_accuracy: 0.6731 - val_loss: 1.1087 - val_precision: 0.7571 - val_recall: 0.7571 - learning_rate: 1.5625e-05\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "  ğŸ“Š Saved: history_customcnn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpz7hjnael\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpz7hjnael\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpz7hjnael'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='keras_tensor_228')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1516231216016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231218896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231218704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231218320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231219472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231217744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231219088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231219280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231217552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231220432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231219856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231220048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231220240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231217936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231221392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231220816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231221008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231221200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231218512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231222352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231221776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231219664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231223120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231222544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… CustomCNN hoÃ n thÃ nh!\n",
      "   Accuracy: 0.7308\n",
      "   Size: 181.66 KB\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸš€ TRAINING: EfficientNetB0\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "TRAINING SET: 748 images\n",
      "  - Fall: 416 (55.6%)\n",
      "  - Not Fall: 332 (44.4%)\n",
      "\n",
      "VALIDATION SET: 222 images\n",
      "  - Fall: 140 (63.1%)\n",
      "  - Not Fall: 82 (36.9%)\n",
      "============================================================\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EfficientNetB0\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"EfficientNetB0\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_7      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,992</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m4,049,571\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_7      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_14 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚        \u001b[38;5;34m40,992\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_15 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,090,596</span> (15.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,090,596\u001b[0m (15.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,025</span> (160.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,025\u001b[0m (160.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.5474 - loss: 0.7063 - precision: 0.6716 - recall: 0.4198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 313ms/step - accuracy: 0.5177 - loss: 0.7070 - precision: 0.5881 - recall: 0.4550 - val_accuracy: 0.6731 - val_loss: 0.6827 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 197ms/step - accuracy: 0.5082 - loss: 0.6987 - precision: 0.5473 - recall: 0.6520 - val_accuracy: 0.3269 - val_loss: 0.7003 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.5340 - loss: 0.6937 - precision: 0.5812 - recall: 0.5627 - val_accuracy: 0.3269 - val_loss: 0.7034 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - accuracy: 0.4579 - loss: 0.6986 - precision: 0.5354 - recall: 0.2567 - val_accuracy: 0.3269 - val_loss: 0.6937 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - accuracy: 0.4620 - loss: 0.6954 - precision: 0.5234 - recall: 0.1667 - val_accuracy: 0.3269 - val_loss: 0.6935 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.4796 - loss: 0.6900 - precision: 0.6267 - recall: 0.2233 - val_accuracy: 0.6731 - val_loss: 0.6750 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 203ms/step - accuracy: 0.4416 - loss: 0.6956 - precision: 0.4731 - recall: 0.1965 - val_accuracy: 0.3269 - val_loss: 0.6935 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - accuracy: 0.4511 - loss: 0.6943 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3269 - val_loss: 0.6941 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 206ms/step - accuracy: 0.4443 - loss: 0.6933 - precision: 0.5000 - recall: 0.0024 - val_accuracy: 0.3269 - val_loss: 0.6938 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - accuracy: 0.4253 - loss: 0.6914 - precision: 0.4691 - recall: 0.0909 - val_accuracy: 0.6731 - val_loss: 0.6931 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 215ms/step - accuracy: 0.4579 - loss: 0.6947 - precision: 0.5306 - recall: 0.0647 - val_accuracy: 0.3269 - val_loss: 0.6939 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 250ms/step - accuracy: 0.4402 - loss: 0.6926 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3269 - val_loss: 0.6939 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 249ms/step - accuracy: 0.4293 - loss: 0.6912 - precision: 0.4938 - recall: 0.0955 - val_accuracy: 0.6731 - val_loss: 0.6929 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.5029 - loss: 0.6976 - precision: 0.5185 - recall: 0.6514\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - accuracy: 0.4674 - loss: 0.6961 - precision: 0.5089 - recall: 0.2879 - val_accuracy: 0.3269 - val_loss: 0.6939 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 223ms/step - accuracy: 0.4443 - loss: 0.6935 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3269 - val_loss: 0.6939 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 245ms/step - accuracy: 0.4348 - loss: 0.6920 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3269 - val_loss: 0.6936 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - accuracy: 0.4293 - loss: 0.6909 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3269 - val_loss: 0.6934 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 205ms/step - accuracy: 0.4552 - loss: 0.6949 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3269 - val_loss: 0.6935 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 205ms/step - accuracy: 0.4511 - loss: 0.6943 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3269 - val_loss: 0.6937 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 202ms/step - accuracy: 0.4457 - loss: 0.6934 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3269 - val_loss: 0.6937 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.4416 - loss: 0.6928 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3269 - val_loss: 0.6937 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "ğŸ”§ Fine-tuning EfficientNetB0...\n",
      "Epoch 1/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 346ms/step - accuracy: 0.5340 - loss: 0.7257 - precision: 0.5994 - recall: 0.4742 - val_accuracy: 0.6731 - val_loss: 0.6828 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 254ms/step - accuracy: 0.5149 - loss: 0.7131 - precision: 0.5846 - recall: 0.4612 - val_accuracy: 0.6731 - val_loss: 0.6797 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 253ms/step - accuracy: 0.5435 - loss: 0.7059 - precision: 0.5887 - recall: 0.6058 - val_accuracy: 0.6731 - val_loss: 0.6845 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 254ms/step - accuracy: 0.5027 - loss: 0.7039 - precision: 0.5625 - recall: 0.4632 - val_accuracy: 0.6731 - val_loss: 0.6840 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 253ms/step - accuracy: 0.5258 - loss: 0.7080 - precision: 0.5742 - recall: 0.5186 - val_accuracy: 0.6731 - val_loss: 0.6782 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 262ms/step - accuracy: 0.5190 - loss: 0.7013 - precision: 0.5844 - recall: 0.5370 - val_accuracy: 0.6731 - val_loss: 0.6750 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 260ms/step - accuracy: 0.5136 - loss: 0.6993 - precision: 0.5777 - recall: 0.4793 - val_accuracy: 0.6731 - val_loss: 0.6742 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 256ms/step - accuracy: 0.5027 - loss: 0.7027 - precision: 0.5500 - recall: 0.5173 - val_accuracy: 0.6731 - val_loss: 0.6834 - val_precision: 0.6731 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 260ms/step - accuracy: 0.5285 - loss: 0.6942 - precision: 0.5870 - recall: 0.4690 - val_accuracy: 0.3269 - val_loss: 0.6964 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 253ms/step - accuracy: 0.5421 - loss: 0.6880 - precision: 0.5958 - recall: 0.6143 - val_accuracy: 0.3269 - val_loss: 0.7284 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 256ms/step - accuracy: 0.4918 - loss: 0.6968 - precision: 0.5518 - recall: 0.5145 - val_accuracy: 0.3462 - val_loss: 0.6977 - val_precision: 1.0000 - val_recall: 0.0286 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 253ms/step - accuracy: 0.5340 - loss: 0.6864 - precision: 0.5920 - recall: 0.4789 - val_accuracy: 0.3269 - val_loss: 0.7322 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.5096 - loss: 0.6995 - precision: 0.5473 - recall: 0.5815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 287ms/step - accuracy: 0.5054 - loss: 0.6905 - precision: 0.5646 - recall: 0.5914 - val_accuracy: 0.6827 - val_loss: 0.6626 - val_precision: 0.6796 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 270ms/step - accuracy: 0.5326 - loss: 0.6980 - precision: 0.5566 - recall: 0.6132 - val_accuracy: 0.6538 - val_loss: 0.6764 - val_precision: 0.7429 - val_recall: 0.7429 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.5327 - loss: 0.6884 - precision: 0.5959 - recall: 0.4909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 268ms/step - accuracy: 0.5489 - loss: 0.6837 - precision: 0.6050 - recall: 0.5368 - val_accuracy: 0.7163 - val_loss: 0.6843 - val_precision: 0.8785 - val_recall: 0.6714 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 254ms/step - accuracy: 0.5340 - loss: 0.6966 - precision: 0.5729 - recall: 0.6578 - val_accuracy: 0.3269 - val_loss: 0.7020 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 254ms/step - accuracy: 0.5408 - loss: 0.6890 - precision: 0.5812 - recall: 0.6570 - val_accuracy: 0.6731 - val_loss: 0.6543 - val_precision: 0.6765 - val_recall: 0.9857 - learning_rate: 1.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step - accuracy: 0.5136 - loss: 0.6921 - precision: 0.5601 - recall: 0.4787 - val_accuracy: 0.6731 - val_loss: 0.6623 - val_precision: 0.6765 - val_recall: 0.9857 - learning_rate: 1.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 253ms/step - accuracy: 0.5258 - loss: 0.6906 - precision: 0.5697 - recall: 0.5907 - val_accuracy: 0.6731 - val_loss: 0.6561 - val_precision: 0.6765 - val_recall: 0.9857 - learning_rate: 1.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 253ms/step - accuracy: 0.5992 - loss: 0.6687 - precision: 0.6571 - recall: 0.6048 - val_accuracy: 0.6538 - val_loss: 0.6573 - val_precision: 0.7576 - val_recall: 0.7143 - learning_rate: 1.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 268ms/step - accuracy: 0.5652 - loss: 0.6742 - precision: 0.6028 - recall: 0.6265 - val_accuracy: 0.6827 - val_loss: 0.6260 - val_precision: 0.6796 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 256ms/step - accuracy: 0.5842 - loss: 0.6728 - precision: 0.6453 - recall: 0.5831 - val_accuracy: 0.6538 - val_loss: 0.6573 - val_precision: 0.7500 - val_recall: 0.7286 - learning_rate: 1.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 245ms/step - accuracy: 0.5421 - loss: 0.6843 - precision: 0.5923 - recall: 0.5648 - val_accuracy: 0.6827 - val_loss: 0.6298 - val_precision: 0.6796 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step - accuracy: 0.5734 - loss: 0.6808 - precision: 0.6250 - recall: 0.5854 - val_accuracy: 0.6731 - val_loss: 0.6174 - val_precision: 0.6765 - val_recall: 0.9857 - learning_rate: 1.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 255ms/step - accuracy: 0.5598 - loss: 0.6857 - precision: 0.5777 - recall: 0.6134 - val_accuracy: 0.6731 - val_loss: 0.6207 - val_precision: 0.6765 - val_recall: 0.9857 - learning_rate: 1.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 254ms/step - accuracy: 0.5598 - loss: 0.6753 - precision: 0.6122 - recall: 0.6383 - val_accuracy: 0.5962 - val_loss: 0.6281 - val_precision: 0.6522 - val_recall: 0.8571 - learning_rate: 1.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 261ms/step - accuracy: 0.5910 - loss: 0.6583 - precision: 0.6256 - recall: 0.6395 - val_accuracy: 0.7067 - val_loss: 0.6497 - val_precision: 0.8496 - val_recall: 0.6857 - learning_rate: 1.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 252ms/step - accuracy: 0.5842 - loss: 0.6699 - precision: 0.6250 - recall: 0.6250 - val_accuracy: 0.6635 - val_loss: 0.6109 - val_precision: 0.6733 - val_recall: 0.9714 - learning_rate: 1.0000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 253ms/step - accuracy: 0.5774 - loss: 0.6729 - precision: 0.6322 - recall: 0.6247 - val_accuracy: 0.6731 - val_loss: 0.6126 - val_precision: 0.6800 - val_recall: 0.9714 - learning_rate: 1.0000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step - accuracy: 0.6033 - loss: 0.6594 - precision: 0.6637 - recall: 0.5619 - val_accuracy: 0.6731 - val_loss: 0.6073 - val_precision: 0.6765 - val_recall: 0.9857 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "  ğŸ“Š Saved: history_efficientnetb0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpx3ila18n\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpx3ila18n\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpx3ila18n'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='keras_tensor_487')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1515719913360: TensorSpec(shape=(1, 1, 1, 3), dtype=tf.float32, name=None)\n",
      "  1515719914704: TensorSpec(shape=(1, 1, 1, 3), dtype=tf.float32, name=None)\n",
      "  1516105603920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105605072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105600464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105604688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105605264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105605648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105602768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105605840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105613136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105612176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105600656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105612560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105604112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105612752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105612368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105602192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105611024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105612944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105610256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105603536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105611792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105610832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105610640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105609296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515548967376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105611216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105609872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105609488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105608912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105610064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105608144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105611600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105608720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105602000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105610448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105607760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105607376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105606416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105607184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105611408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105606992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105606800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105605456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105606224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105608528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105606608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105609680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105600272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105606032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105607952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516105607568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251166096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251164944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251164368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251164752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251165328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251164176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251163600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251168400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251165904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251163984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251162640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251167824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251165136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251163216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251163024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251161680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251162448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251162064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251163408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251162256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251161488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251163792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251160720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251162832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251160336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251164560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251160528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251160912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251159568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251159376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251159760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251161104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251159952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251158608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251158416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251158800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251157648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251161296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251158992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251157840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251160144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251157456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251159184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251157072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251156496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251156688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251158224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251155728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251155536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251157264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251156880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251156112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251154768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251154576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251154960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251153808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251155920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251155152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251154000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251156304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251153616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251155344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251153232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251158032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251153040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251153424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251152464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251167440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251152656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251152848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251167632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251167248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251167056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251168592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251161872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251154384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251166672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251166288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251166864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251166480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251154192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251168208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256441936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256438672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256439056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256441552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256441168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256440976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256438864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256437520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256439248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256437712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256437904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256442320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256440400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256439440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256442128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256440592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256442896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256441744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256443664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256443856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256443280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256441360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256442704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256443088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256444240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256442512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251595216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256443472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516256444048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251594832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251596560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251595600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251595408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251596368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251595984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251597136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251595792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251597904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251595024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251597328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251597712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251598288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251598864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251598096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251597520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251598672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251599248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251599824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251599056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251600208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251596944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251599632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251600016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251598480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251600784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251599440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251601552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251601744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251601168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251600400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251602128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251602704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251601360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251600976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251602512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251603088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251603664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251602896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251604048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251601936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251603472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251603856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251602320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251604624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251603280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251605392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251605584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251605008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251604240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251605968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251606544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251605200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251604816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251606352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251606928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251607504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251606736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251607888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251605776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251607312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251607696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251606160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251608464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251607120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251609232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251604432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251608656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251609040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251609616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251610192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251609424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251610000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251610384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251596752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251609808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251610768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251608272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251608848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251608080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251610576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719901648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719902800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516251610960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719902224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719903184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719902032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719902992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719903568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719904144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719901840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719902416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719903952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719904528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719905104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719904336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719905488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719903376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719904912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719905296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719903760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719906064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719904720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719906832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719907024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719906448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719905680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719907408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719907984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719906640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719906256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719907792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719908368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719908944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719908176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719909328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719907216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719908752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719909136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719907600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719909904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719908560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719910672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719910864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719910288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719909520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719911248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719911824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719910480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719910096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719911632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719912208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719912784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719912016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719913168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719911056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719912592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719912976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719911440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719913744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719912400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719914512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719909712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719913936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719914320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719914896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719915472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719915664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719901456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719916624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1515719915856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… EfficientNetB0 hoÃ n thÃ nh!\n",
      "   Accuracy: 0.7163\n",
      "   Size: 4835.48 KB\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸš€ TRAINING: SimpleCNN\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "TRAINING SET: 748 images\n",
      "  - Fall: 416 (55.6%)\n",
      "  - Not Fall: 332 (44.4%)\n",
      "\n",
      "VALIDATION SET: 222 images\n",
      "  - Fall: 140 (63.1%)\n",
      "  - Not Fall: 82 (36.9%)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SimpleCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SimpleCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_19          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_20          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_21          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_8      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   â”‚           \u001b[38;5;34m432\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_19          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   â”‚            \u001b[38;5;34m64\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚         \u001b[38;5;34m4,608\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_20          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_8 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚        \u001b[38;5;34m18,432\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_21          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_9 (\u001b[38;5;33mActivation\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_8      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_16 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,985</span> (93.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,985\u001b[0m (93.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,761</span> (92.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,761\u001b[0m (92.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5656 - loss: 0.6828 - precision: 0.6380 - recall: 0.5685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 150ms/step - accuracy: 0.5720 - loss: 0.6969 - precision: 0.6280 - recall: 0.5683 - val_accuracy: 0.5577 - val_loss: 0.6836 - val_precision: 0.8000 - val_recall: 0.4571 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.6417 - loss: 0.6241 - precision: 0.7041 - recall: 0.6597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.6440 - loss: 0.6347 - precision: 0.6856 - recall: 0.6552 - val_accuracy: 0.6154 - val_loss: 0.6525 - val_precision: 0.7885 - val_recall: 0.5857 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6413 - loss: 0.6383 - precision: 0.6917 - recall: 0.6481 - val_accuracy: 0.5577 - val_loss: 0.6979 - val_precision: 0.8000 - val_recall: 0.4571 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.6328 - loss: 0.6336 - precision: 0.6855 - recall: 0.6237"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.6332 - loss: 0.6364 - precision: 0.6878 - recall: 0.6133 - val_accuracy: 0.6635 - val_loss: 0.6149 - val_precision: 0.6768 - val_recall: 0.9571 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.6834 - loss: 0.5881 - precision: 0.7297 - recall: 0.6814 - val_accuracy: 0.6635 - val_loss: 0.7163 - val_precision: 0.6699 - val_recall: 0.9857 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.6807 - loss: 0.5852 - precision: 0.7263 - recall: 0.6781 - val_accuracy: 0.5769 - val_loss: 0.6613 - val_precision: 0.6711 - val_recall: 0.7286 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 153ms/step - accuracy: 0.7120 - loss: 0.5836 - precision: 0.7538 - recall: 0.7171 - val_accuracy: 0.6635 - val_loss: 0.6640 - val_precision: 0.6804 - val_recall: 0.9429 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7004 - loss: 0.5851 - precision: 0.7612 - recall: 0.7095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.7052 - loss: 0.5706 - precision: 0.7537 - recall: 0.7271 - val_accuracy: 0.6731 - val_loss: 0.6096 - val_precision: 0.6915 - val_recall: 0.9286 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.7269 - loss: 0.5579 - precision: 0.7634 - recall: 0.7353 - val_accuracy: 0.5288 - val_loss: 0.6661 - val_precision: 0.6721 - val_recall: 0.5857 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7028 - loss: 0.5686 - precision: 0.7176 - recall: 0.7232"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.7160 - loss: 0.5489 - precision: 0.7474 - recall: 0.7270 - val_accuracy: 0.6827 - val_loss: 0.6722 - val_precision: 0.6869 - val_recall: 0.9714 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7242 - loss: 0.5377 - precision: 0.7719 - recall: 0.7132 - val_accuracy: 0.6731 - val_loss: 0.9045 - val_precision: 0.6765 - val_recall: 0.9857 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.6896 - loss: 0.5779 - precision: 0.7160 - recall: 0.7170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.6970 - loss: 0.5643 - precision: 0.7311 - recall: 0.7257 - val_accuracy: 0.6923 - val_loss: 0.6418 - val_precision: 0.7500 - val_recall: 0.8143 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.7500 - loss: 0.5249 - precision: 0.7948 - recall: 0.7445 - val_accuracy: 0.6923 - val_loss: 0.6710 - val_precision: 0.6863 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 156ms/step - accuracy: 0.7568 - loss: 0.5330 - precision: 0.7850 - recall: 0.7715 - val_accuracy: 0.6923 - val_loss: 0.8646 - val_precision: 0.6863 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.7133 - loss: 0.5511 - precision: 0.7506 - recall: 0.7192 - val_accuracy: 0.6923 - val_loss: 0.8197 - val_precision: 0.6863 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7460 - loss: 0.5238 - precision: 0.7716 - recall: 0.7818\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.7514 - loss: 0.5299 - precision: 0.7778 - recall: 0.7797 - val_accuracy: 0.3365 - val_loss: 2.1377 - val_precision: 1.0000 - val_recall: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.7230 - loss: 0.5593 - precision: 0.7396 - recall: 0.7524"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7269 - loss: 0.5436 - precision: 0.7583 - recall: 0.7376 - val_accuracy: 0.7019 - val_loss: 0.6082 - val_precision: 0.7143 - val_recall: 0.9286 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.7853 - loss: 0.4791 - precision: 0.8102 - recall: 0.8063 - val_accuracy: 0.6827 - val_loss: 0.6764 - val_precision: 0.7229 - val_recall: 0.8571 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.7527 - loss: 0.5170 - precision: 0.7816 - recall: 0.7702 - val_accuracy: 0.6827 - val_loss: 0.7745 - val_precision: 0.6869 - val_recall: 0.9714 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.7242 - loss: 0.5241 - precision: 0.7374 - recall: 0.7859 - val_accuracy: 0.5673 - val_loss: 0.7638 - val_precision: 0.7193 - val_recall: 0.5857 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - accuracy: 0.7880 - loss: 0.4886 - precision: 0.8111 - recall: 0.8111 - val_accuracy: 0.7019 - val_loss: 0.7695 - val_precision: 0.7294 - val_recall: 0.8857 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 0.7595 - loss: 0.5049 - precision: 0.7925 - recall: 0.7713 - val_accuracy: 0.6346 - val_loss: 0.5853 - val_precision: 0.7667 - val_recall: 0.6571 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7785 - loss: 0.4712 - precision: 0.7859 - recall: 0.8227 - val_accuracy: 0.6923 - val_loss: 1.0405 - val_precision: 0.6900 - val_recall: 0.9857 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7677 - loss: 0.5138 - precision: 0.7901 - recall: 0.7882 - val_accuracy: 0.5865 - val_loss: 0.8077 - val_precision: 0.7077 - val_recall: 0.6571 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7649 - loss: 0.4941 - precision: 0.7797 - recall: 0.7970 - val_accuracy: 0.6923 - val_loss: 0.6872 - val_precision: 0.7375 - val_recall: 0.8429 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.7663 - loss: 0.4930 - precision: 0.8029 - recall: 0.7838 - val_accuracy: 0.6923 - val_loss: 0.5643 - val_precision: 0.7436 - val_recall: 0.8286 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.7758 - loss: 0.4891 - precision: 0.7975 - recall: 0.7916 - val_accuracy: 0.5096 - val_loss: 1.0611 - val_precision: 0.7879 - val_recall: 0.3714 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7758 - loss: 0.4774 - precision: 0.7986 - recall: 0.8043 - val_accuracy: 0.5096 - val_loss: 0.8633 - val_precision: 0.6792 - val_recall: 0.5143 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 163ms/step - accuracy: 0.7717 - loss: 0.4762 - precision: 0.8125 - recall: 0.7647 - val_accuracy: 0.6923 - val_loss: 0.7284 - val_precision: 0.7375 - val_recall: 0.8429 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 177ms/step - accuracy: 0.8057 - loss: 0.4395 - precision: 0.8177 - recall: 0.8358 - val_accuracy: 0.6827 - val_loss: 0.9571 - val_precision: 0.7284 - val_recall: 0.8429 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.7772 - loss: 0.4744 - precision: 0.7951 - recall: 0.8030 - val_accuracy: 0.6538 - val_loss: 0.6845 - val_precision: 0.7576 - val_recall: 0.7143 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.8152 - loss: 0.4396 - precision: 0.8401 - recall: 0.8361 - val_accuracy: 0.6923 - val_loss: 0.6236 - val_precision: 0.7500 - val_recall: 0.8143 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.7758 - loss: 0.4693 - precision: 0.7740 - recall: 0.8193 - val_accuracy: 0.6923 - val_loss: 0.8972 - val_precision: 0.6979 - val_recall: 0.9571 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7788 - loss: 0.4737 - precision: 0.8138 - recall: 0.7665\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.7758 - loss: 0.4752 - precision: 0.8157 - recall: 0.7783 - val_accuracy: 0.6923 - val_loss: 0.9117 - val_precision: 0.6900 - val_recall: 0.9857 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.8102 - loss: 0.4494 - precision: 0.8298 - recall: 0.8278"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8003 - loss: 0.4562 - precision: 0.8228 - recall: 0.8208 - val_accuracy: 0.7115 - val_loss: 0.7772 - val_precision: 0.7128 - val_recall: 0.9571 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8193 - loss: 0.4409 - precision: 0.8103 - recall: 0.8693 - val_accuracy: 0.7115 - val_loss: 0.8037 - val_precision: 0.7703 - val_recall: 0.8143 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8247 - loss: 0.4143 - precision: 0.8486 - recall: 0.8425 - val_accuracy: 0.7115 - val_loss: 0.7234 - val_precision: 0.7500 - val_recall: 0.8571 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8247 - loss: 0.4084 - precision: 0.8200 - recall: 0.8597 - val_accuracy: 0.7019 - val_loss: 0.8779 - val_precision: 0.7468 - val_recall: 0.8429 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8191 - loss: 0.4118 - precision: 0.8583 - recall: 0.8276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.8003 - loss: 0.4328 - precision: 0.8454 - recall: 0.8083 - val_accuracy: 0.7404 - val_loss: 0.6293 - val_precision: 0.7792 - val_recall: 0.8571 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.7976 - loss: 0.4456 - precision: 0.7971 - recall: 0.8316 - val_accuracy: 0.6827 - val_loss: 0.9693 - val_precision: 0.7467 - val_recall: 0.8000 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8030 - loss: 0.4443 - precision: 0.8492 - recall: 0.7991 - val_accuracy: 0.6923 - val_loss: 1.1350 - val_precision: 0.6939 - val_recall: 0.9714 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7957 - loss: 0.4405 - precision: 0.8214 - recall: 0.8236\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.8071 - loss: 0.4335 - precision: 0.8071 - recall: 0.8475 - val_accuracy: 0.7115 - val_loss: 1.1459 - val_precision: 0.7041 - val_recall: 0.9857 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8288 - loss: 0.3983 - precision: 0.8575 - recall: 0.8369 - val_accuracy: 0.7308 - val_loss: 0.8489 - val_precision: 0.7692 - val_recall: 0.8571 - learning_rate: 1.2500e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.8342 - loss: 0.4098 - precision: 0.8491 - recall: 0.8533 - val_accuracy: 0.6154 - val_loss: 0.9105 - val_precision: 0.7419 - val_recall: 0.6571 - learning_rate: 1.2500e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - accuracy: 0.8166 - loss: 0.4188 - precision: 0.8289 - recall: 0.8391 - val_accuracy: 0.7115 - val_loss: 0.9221 - val_precision: 0.7500 - val_recall: 0.8571 - learning_rate: 1.2500e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - accuracy: 0.8329 - loss: 0.3914 - precision: 0.8534 - recall: 0.8555 - val_accuracy: 0.7212 - val_loss: 0.8135 - val_precision: 0.7662 - val_recall: 0.8429 - learning_rate: 1.2500e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 157ms/step - accuracy: 0.8193 - loss: 0.4164 - precision: 0.8254 - recall: 0.8401 - val_accuracy: 0.5962 - val_loss: 0.8910 - val_precision: 0.7333 - val_recall: 0.6286 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.8397 - loss: 0.4135 - precision: 0.8533 - recall: 0.8575 - val_accuracy: 0.7212 - val_loss: 0.7752 - val_precision: 0.7733 - val_recall: 0.8286 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 151ms/step - accuracy: 0.8139 - loss: 0.4076 - precision: 0.8333 - recall: 0.8313 - val_accuracy: 0.6442 - val_loss: 0.9666 - val_precision: 0.7463 - val_recall: 0.7143 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.8000 - loss: 0.4168 - precision: 0.8311 - recall: 0.8154\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.8247 - loss: 0.3918 - precision: 0.8488 - recall: 0.8386 - val_accuracy: 0.6827 - val_loss: 0.9716 - val_precision: 0.7467 - val_recall: 0.8000 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - accuracy: 0.8111 - loss: 0.4162 - precision: 0.8238 - recall: 0.8418 - val_accuracy: 0.6923 - val_loss: 0.8385 - val_precision: 0.7568 - val_recall: 0.8000 - learning_rate: 6.2500e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step - accuracy: 0.8342 - loss: 0.3916 - precision: 0.8540 - recall: 0.8499 - val_accuracy: 0.7212 - val_loss: 0.9962 - val_precision: 0.7531 - val_recall: 0.8714 - learning_rate: 6.2500e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.8207 - loss: 0.4031 - precision: 0.8446 - recall: 0.8280 - val_accuracy: 0.6923 - val_loss: 0.9006 - val_precision: 0.7714 - val_recall: 0.7714 - learning_rate: 6.2500e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - accuracy: 0.8247 - loss: 0.4024 - precision: 0.8298 - recall: 0.8603 - val_accuracy: 0.6058 - val_loss: 0.9499 - val_precision: 0.7377 - val_recall: 0.6429 - learning_rate: 6.2500e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - accuracy: 0.8356 - loss: 0.4024 - precision: 0.8432 - recall: 0.8659 - val_accuracy: 0.5385 - val_loss: 0.9799 - val_precision: 0.7037 - val_recall: 0.5429 - learning_rate: 6.2500e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.8397 - loss: 0.3885 - precision: 0.8557 - recall: 0.8557 - val_accuracy: 0.6442 - val_loss: 0.9277 - val_precision: 0.7538 - val_recall: 0.7000 - learning_rate: 6.2500e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.8410 - loss: 0.4069 - precision: 0.8493 - recall: 0.8680 - val_accuracy: 0.7212 - val_loss: 0.9422 - val_precision: 0.7470 - val_recall: 0.8857 - learning_rate: 6.2500e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.8441 - loss: 0.3843 - precision: 0.8906 - recall: 0.8389\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.8370 - loss: 0.3953 - precision: 0.8540 - recall: 0.8498 - val_accuracy: 0.7404 - val_loss: 0.9187 - val_precision: 0.7722 - val_recall: 0.8714 - learning_rate: 6.2500e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8424 - loss: 0.3949 - precision: 0.8741 - recall: 0.8402 - val_accuracy: 0.6635 - val_loss: 0.9597 - val_precision: 0.7612 - val_recall: 0.7286 - learning_rate: 3.1250e-05\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "  ğŸ“Š Saved: history_simplecnn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpq9qbipll\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpq9qbipll\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpq9qbipll'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='keras_tensor_494')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1516722714192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722715536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722715344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722714960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722716112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516231214480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722715728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722714576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722714384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722715152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722716304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722715920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516692914832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722716496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516722713808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516692914448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516692914256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… SimpleCNN hoÃ n thÃ nh!\n",
      "   Accuracy: 0.7404\n",
      "   Size: 30.01 KB\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Káº¾T QUáº¢ SO SÃNH\n",
      "============================================================\n",
      "Model                Accuracy     Precision    Recall       Size (KB)   \n",
      "------------------------------------------------------------\n",
      "MobileNetV2          0.8413       0.9023       0.8571       647.43      \n",
      "SimpleCNN            0.7404       0.7792       0.8571       30.01       \n",
      "CustomCNN            0.7308       0.7442       0.9143       181.66      \n",
      "EfficientNetB0       0.7163       0.8785       0.6714       4835.48     \n",
      "============================================================\n",
      "\n",
      "ğŸ† KHUYáº¾N NGHá»Š:\n",
      "  â€¢ ChÃ­nh xÃ¡c nháº¥t: MobileNetV2 (Acc: 0.8413)\n",
      "  â€¢ Nhá» nháº¥t: SimpleCNN (Size: 30.01 KB)\n",
      "\n",
      "ğŸ’¡ Äá»ƒ triá»ƒn khai ESP32, dÃ¹ng: mobilenetv2_model.tflite\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    DATA_DIR = \"D:\\\\UET courses\\\\IOT and Application\\\\Fall_detection\\\\Data\\\\images\"\n",
    "    \n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        print(f\" ERROR: ThÆ° má»¥c {DATA_DIR} khÃ´ng tá»“n táº¡i!\")\n",
    "        print(\"\\n Cáº¥u trÃºc cáº§n cÃ³:\")\n",
    "        print(\"images/\")\n",
    "        print(\"  â”œâ”€â”€ train/\")\n",
    "        print(\"  â”‚   â”œâ”€â”€ fall*.jpg\")\n",
    "        print(\"  â”‚   â””â”€â”€ not_fall*.jpg\")\n",
    "        print(\"  â””â”€â”€ valid/\")\n",
    "        print(\"      â”œâ”€â”€ fall*.jpg\")\n",
    "        print(\"      â””â”€â”€ not_fall*.jpg\")\n",
    "    else:\n",
    "        # Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘á»ƒ thá»­\n",
    "        models_to_try = [\n",
    "            'MobileNetV2',     # RECOMMENDED - tá»‘t nháº¥t cho ESP32\n",
    "            'CustomCNN',       # CÃ¢n báº±ng\n",
    "            'EfficientNetB0',  # ChÃ­nh xÃ¡c cao nhÆ°ng lá»›n hÆ¡n\n",
    "            'SimpleCNN'        # Nhá» nháº¥t nhÆ°ng cÃ³ thá»ƒ kÃ©m chÃ­nh xÃ¡c\n",
    "        ]\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ”¬ EXPERIMENT: So sÃ¡nh cÃ¡c kiáº¿n trÃºc mÃ´ hÃ¬nh\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for model_name in models_to_try:\n",
    "            try:\n",
    "                # Train\n",
    "                model, history, val_results = train_model(model_name, DATA_DIR)\n",
    "                \n",
    "                # Save\n",
    "                model.save(f'{model_name.lower()}_model.h5')\n",
    "                \n",
    "                # Convert to TFLite\n",
    "                tflite_path, size_kb = convert_to_tflite(model, model_name)\n",
    "                \n",
    "                # Store results\n",
    "                val_acc = val_results[1]  # accuracy\n",
    "                val_precision = val_results[2] if len(val_results) > 2 else 0\n",
    "                val_recall = val_results[3] if len(val_results) > 3 else 0\n",
    "                \n",
    "                results.append({\n",
    "                    'name': model_name,\n",
    "                    'val_acc': val_acc,\n",
    "                    'precision': val_precision,\n",
    "                    'recall': val_recall,\n",
    "                    'size_kb': size_kb,\n",
    "                    'tflite_path': tflite_path\n",
    "                })\n",
    "                \n",
    "                print(f\"\\nâœ… {model_name} hoÃ n thÃ nh!\")\n",
    "                print(f\"   Accuracy: {val_acc:.4f}\")\n",
    "                print(f\"   Size: {size_kb:.2f} KB\\n\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâŒ Lá»—i khi train {model_name}: {str(e)}\\n\")\n",
    "                continue\n",
    "        \n",
    "        # So sÃ¡nh káº¿t quáº£\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ“Š Káº¾T QUáº¢ SO SÃNH\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"{'Model':<20} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'Size (KB)':<12}\")\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        for r in sorted(results, key=lambda x: x['val_acc'], reverse=True):\n",
    "            print(f\"{r['name']:<20} {r['val_acc']:<12.4f} {r['precision']:<12.4f} {r['recall']:<12.4f} {r['size_kb']:<12.2f}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Recommendation\n",
    "        if results:\n",
    "            best_acc = max(results, key=lambda x: x['val_acc'])\n",
    "            best_size = min(results, key=lambda x: x['size_kb'])\n",
    "            \n",
    "            print(\"\\nğŸ† KHUYáº¾N NGHá»Š:\")\n",
    "            print(f\"  â€¢ ChÃ­nh xÃ¡c nháº¥t: {best_acc['name']} (Acc: {best_acc['val_acc']:.4f})\")\n",
    "            print(f\"  â€¢ Nhá» nháº¥t: {best_size['name']} (Size: {best_size['size_kb']:.2f} KB)\")\n",
    "            print(f\"\\nğŸ’¡ Äá»ƒ triá»ƒn khai ESP32, dÃ¹ng: {best_acc['tflite_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7c1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
